{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import tqdm\n",
    "import re\n",
    "import json\n",
    "import calendar\n",
    "import datetime\n",
    "import random\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import uuid\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent_list = [\n",
    "   #Chrome\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    #Firefox\n",
    "    'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    page = Request(url, headers = {\"User-Agent\": random.choice(user_agent_list)})\n",
    "    html = urlopen(page, context = ctx).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def get_companies(url):\n",
    "    soup = get_soup(url).tbody\n",
    "    tags = soup('tr')\n",
    "    companies = [tag.find_all('a')[1].text for tag in tags]\n",
    "    return companies\n",
    "\n",
    "def prepend_zero(i):\n",
    "    return '0'+ str(i) if i < 10 else i\n",
    "\n",
    "def shorten_months(s):\n",
    "    months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'sept', 'october', 'november', 'december']\n",
    "    for month in months:\n",
    "        s = s.replace(month, month[:3])\n",
    "    return s\n",
    "\n",
    "def get_dt(date_html):\n",
    "    date_block = date_html.find(id='date')\n",
    "    time_block = date_html.find(id='time')\n",
    "    \n",
    "    if date_block:\n",
    "        date = date_block.text.lower().replace('.', '')\n",
    "        date = shorten_months(date)\n",
    "    else:\n",
    "        regex_query = '(jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)\\.* [0-9]*[0-9], [0-9][0-9][0-9][0-9]'\n",
    "        date = re.search(regex_query, date_html.text.lower())\n",
    "        if date is None:\n",
    "            print('Could not find date!', date_html.text, '\\n')\n",
    "        else:\n",
    "            date = date[0].replace('.','')\n",
    "            splits = date.split(' ')\n",
    "            if len(splits[1]) == 2:\n",
    "                splits[1] = '0'+splits[1]\n",
    "            date = ' '.join(splits)\n",
    "            date = shorten_months(date)\n",
    "            \n",
    "    dt = None\n",
    "    dt_time = None\n",
    "    \n",
    "    if time_block:\n",
    "        time = time_block.text\n",
    "        [time, ampm, time_zone] = time.split(' ')\n",
    "        if len(time) == 4:\n",
    "            time = '0'+time\n",
    "        ampm = ampm.replace('.', '')\n",
    "        dt_time = datetime.datetime.strptime(f'{time} {ampm}', \"%I:%M %p\").time()\n",
    "    else:\n",
    "        regex_query = '[0-9]*[0-9]:[0-9][0-9] (a\\.*m\\.*|p\\.*m\\.*)'\n",
    "        time = re.search(regex_query, date_html.text.lower())\n",
    "        if time is None:\n",
    "            print('Could not find time!', date_html.text, '\\n')\n",
    "        else:\n",
    "            time = time[0]\n",
    "            time = time.replace('.', '')\n",
    "            [time, ampm] = time.split(' ')\n",
    "            if len(time) == 4:\n",
    "                time = '0'+time\n",
    "            dt_time = datetime.datetime.strptime(f'{time} {ampm}', \"%I:%M %p\").time()\n",
    "            \n",
    "    if date is not None:\n",
    "        dt = datetime.datetime.strptime(date, '%b %d, %Y')\n",
    "            \n",
    "    if dt_time is None:\n",
    "        return dt, dt_time\n",
    "    \n",
    "    mkt_open = datetime.time(hour = 9, minute = 30, second = 0)\n",
    "    mkt_close = datetime.time(hour = 16, minute = 0, second = 0)\n",
    "    \n",
    "    after_close = dt_time > mkt_close\n",
    "    \n",
    "    return dt, after_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SSL Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "month_dict = {v: prepend_zero(k) for k,v in enumerate(calendar.month_abbr)}\n",
    "full_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = get_companies(\"http://www.slickcharts.com/sp500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcript_urls.json', 'r') as inp:\n",
    "    transcript_urls = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_completed = []\n",
    "for company, quarters in transcript_urls.items():\n",
    "    for qtr, data in quarters.items():\n",
    "        if 'transcript' in data:\n",
    "            companies_completed.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(companies_completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_urls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions ctd.\n",
    "def get_transcripts(companies, transcript_urls=None):\n",
    "    if transcript_urls is None:\n",
    "        transcript_urls = {}\n",
    "#     for company in tqdm.tqdm_notebook(companies):\n",
    "#         try:\n",
    "#             url = f\"https://www.fool.com/search/solr.aspx?q={company}%20earnings%20call%20transcript\"\n",
    "#             soup = get_soup(url)\n",
    "#             result = soup.find_all(\"dl\", class_ = \"results\")[0]\n",
    "#             transcript_urls[company] = {}\n",
    "#             for link in result.find_all('dt'):\n",
    "#                 period = re.search('Q[0-9] [0-9][0-9][0-9][0-9]', link.text)\n",
    "#                 if period is None:\n",
    "#                     print(f'Skipping non-earnings call transcript url:{link.text}')\n",
    "#                 else:\n",
    "#                     url = link.a.get('href')\n",
    "#                     transcript_urls[company][period[0]] = { 'url': url }\n",
    "#         except:\n",
    "#             print(f'Couldn\\'t get transcripts for company {company}')\n",
    "#             continue\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for company, urls in tqdm.tqdm_notebook(transcript_urls.items()):\n",
    "        if company in companies_completed:\n",
    "            continue\n",
    "        quarters = list(urls.keys())\n",
    "        np.random.shuffle(quarters)\n",
    "        \n",
    "        NUM_QUARTERS = 3\n",
    "        quarters = quarters[:NUM_QUARTERS]\n",
    "        \n",
    "        for quarter in quarters:\n",
    "            data = urls[quarter]\n",
    "            soup = get_soup(data['url'])\n",
    "            text = soup.find('span', class_ = 'article-content').find_all(\"p\")\n",
    "            early_lines = text[:3]\n",
    "            dt_info = early_lines[0]\n",
    "            for line in early_lines[1:]:\n",
    "                dt_info.append(line)\n",
    "            date, hours = get_dt(dt_info)\n",
    "\n",
    "            try:\n",
    "                mcap_soup = get_soup(f\"http://www.zacks.com/stock/quote/{company}\")\n",
    "                for tr in mcap_soup.find_all(\"table\", class_ = \"abut_bottom\"):\n",
    "                    for td in tr.find_all(\"td\"):\n",
    "                        if td.text == \"Market Cap\":\n",
    "                            mkt_cap = td.text + \" \" + td.find_next(\"td\").text\n",
    "                transcript_urls[company][quarter].update({\n",
    "                    \"transcript\": str(soup),\n",
    "                    \"quarter\": quarter,\n",
    "                    \"date\": date.strftime('%b %d, %Y'),\n",
    "                    \"after_market\": bool(hours) if hours is not None else None,\n",
    "                    \"market_cap\": mkt_cap\n",
    "                })\n",
    "            except:\n",
    "                print(f'Couldn\\'t get stock information for {company} {quarter}')\n",
    "        count += 1\n",
    "        if count % 20 == 0:\n",
    "            print('Saving transcripts...')\n",
    "            with open('transcript_urls.json', 'w') as out:\n",
    "                json.dump(transcript_urls, out, indent=2)\n",
    "            print('Do you want to continue?')\n",
    "            contin = input()\n",
    "            if not contin:\n",
    "                return\n",
    "    return transcript_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transcripts(companies, transcript_urls)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign unique identifiers to transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company, quarters in transcript_urls.items():\n",
    "    for quarter, data in quarters.items():\n",
    "        if data.get('transcript') and data.get('date') and data.get('after_market') is not None:\n",
    "            data['id'] = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcript_urls.json', 'w') as out:\n",
    "    json.dump(transcript_urls, out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map ID to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for company, quarters in transcript_urls.items():\n",
    "    for quarter, data in quarters.items():\n",
    "        if 'id' in data:\n",
    "            mapping[data['id']] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter transcripts dictionary to only those that were collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcript_urls.json', 'r') as inp:\n",
    "    transcript_urls = json.load(inp)\n",
    "\n",
    "valid_transcripts = []\n",
    "for company, quarters in transcript_urls.items():\n",
    "    for quarter, data in quarters.items():\n",
    "        if data.get('transcript') and data.get('date') and data.get('after_market') is not None:\n",
    "            valid_transcripts.append({\n",
    "                'id': data['id'],\n",
    "                'company': company,\n",
    "                'quarter': quarter,\n",
    "                'after_market': data['after_market'],\n",
    "                'market_cap': data['market_cap'],\n",
    "                'transcript': data['transcript'],\n",
    "                'date': data['date'],\n",
    "                'url': url\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add stock data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58eabf7a20b43019ef92f11385b4f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=583), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n",
      "'history'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5ef481eb75a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{base}symbol={symbol}&date_from={date_from}&date_to={date_to}&api_token={token}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Append stock info from days before/after earnings\n",
    "# Don't run this on the entire company list, API token will fail out\n",
    "# Split into 200/200/100 with API tokens:\n",
    "\n",
    "# TODO: add in your own API tokens\n",
    "\n",
    "tokens = [token1, token2, token3, token3, token5, sean_token]\n",
    "\n",
    "for transcript in tqdm.tqdm_notebook(invalid_transcripts):\n",
    "    if 'historical_info' in transcript:\n",
    "        continue\n",
    "    token = np.random.choice(tokens)\n",
    "    base = \"https://api.worldtradingdata.com/api/v1/history?\"\n",
    "    symbol = transcript['company']\n",
    "\n",
    "    script_date = datetime.datetime.strptime(transcript['date'], '%b %d, %Y')\n",
    "\n",
    "    change = datetime.timedelta(days = 1)\n",
    "    day1 = script_date + change\n",
    "    day2 = day1 + change\n",
    "    day3 = day2 + change\n",
    "\n",
    "    date_from = (script_date - datetime.timedelta(days = 10)).strftime(\"%Y-%m-%d\")\n",
    "    date_to = (script_date + datetime.timedelta(days = 3)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    try:\n",
    "        url = f\"{base}symbol={symbol}&date_from={date_from}&date_to={date_to}&api_token={token}\"\n",
    "        response = urlopen(url)\n",
    "        info = literal_eval(response.read().decode('utf-8'))\n",
    "\n",
    "        if transcript['after_market'] == 0:\n",
    "            # Script was reported before market hours so post-earnings day is current day\n",
    "            next_day = script_date\n",
    "        else:\n",
    "            # Script was reported after market hours so post-earnings day is next day\n",
    "            if day1.strftime(\"%Y-%m-%d\") in info['history']:\n",
    "                next_day = day1\n",
    "            elif day2.strftime(\"%Y-%m-%d\") in info['history']:\n",
    "                next_day = day2\n",
    "            else:\n",
    "                next_day = day3\n",
    "\n",
    "#         print(symbol)\n",
    "        transcript[\"post_high_low\"] = (info['history'][next_day.strftime(\"%Y-%m-%d\")]['high'], \n",
    "                                               info['history'][next_day.strftime(\"%Y-%m-%d\")]['low'])\n",
    "\n",
    "        history_info = []\n",
    "        days_recorded = 0\n",
    "        num_days = 1\n",
    "        while days_recorded < 5:\n",
    "            days_before = next_day - datetime.timedelta(days = num_days)\n",
    "            if days_before.strftime(\"%Y-%m-%d\") in info['history']:\n",
    "                history_info.append((days_before.strftime(\"%Y-%m-%d\"), \n",
    "                                     (info['history'][days_before.strftime(\"%Y-%m-%d\")]['high'],\n",
    "                                      info['history'][days_before.strftime(\"%Y-%m-%d\")]['low'])))\n",
    "                days_recorded += 1\n",
    "            num_days += 1\n",
    "        transcript[\"historical_info\"] = history_info\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to entries where the API worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transcripts_with_stock_data = []\n",
    "invalid_transcripts = []\n",
    "for transcript in valid_transcripts:\n",
    "    if transcript.get('historical_info'):\n",
    "        valid_transcripts_with_stock_data.append(transcript)\n",
    "    else:\n",
    "        invalid_transcripts.append(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_transcripts_with_stock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcript_full_data.json', 'w') as out:\n",
    "    json.dump(valid_transcripts_with_stock_data, out, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Transcript Issue with new scrapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a97481f554d049d25a6c2bc5e476f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=909), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for transcript in tqdm.tqdm_notebook(valid_transcripts_with_stock_data):\n",
    "    url = mapping[transcript['id']]['url']\n",
    "    transcript['url'] = url\n",
    "    soup = get_soup(transcript['url'])\n",
    "    transcript['transcript'] = str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcript_full_data.json', 'r') as inp:\n",
    "    valid_transcripts_with_stock_data = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and filter transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ece0227afa74e9d8139ecb5671d3484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=909), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for transcript in tqdm.tqdm_notebook(valid_transcripts_with_stock_data):\n",
    "    html = transcript['transcript']\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    text = soup.find('span', class_ = 'article-content').find_all('p')\n",
    "    text = list(filter(lambda x: not x.get('class') and not x.find_all('a'), text))\n",
    "    new_text = []\n",
    "    for p in reversed(text):\n",
    "        if new_text:\n",
    "            new_text.append(p)\n",
    "            continue\n",
    "        if p.text == '':\n",
    "            continue\n",
    "        if p.find_all('strong'):\n",
    "            continue\n",
    "        new_text.append(p)\n",
    "    new_text.reverse()\n",
    "\n",
    "    SPEAKER_START = '_SP_START_'\n",
    "    SPEAKER_END = '_SP_END_'\n",
    "\n",
    "    final_text = []\n",
    "    for p in new_text:\n",
    "        text_to_add = ''\n",
    "        add_speaker = False\n",
    "        if p.find_all('strong'):\n",
    "            add_speaker = True\n",
    "            text_to_add = p.text\n",
    "        else:\n",
    "            text_to_add = p.text\n",
    "        text_to_add = text_to_add.lower()\n",
    "        text_to_add = text_to_add.translate(str.maketrans('', '', string.punctuation))\n",
    "        if add_speaker:\n",
    "            text_to_add = ' '.join([SPEAKER_START, text_to_add, SPEAKER_END])\n",
    "        text_to_add = nltk.word_tokenize(text_to_add)\n",
    "        final_text.append(text_to_add)\n",
    "        \n",
    "    transcript['transcript'] = final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sentences(lines):\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        new_tokens = [] \n",
    "        regexes = [\n",
    "            '[0-9]+', 'million(s)*$', '(m)*m$', '[0-9]+(m)*m$', \n",
    "            '[0-9]+(b*)b$', 'trillion(s)*$', '[0-9]+t$', 'thousand(s)*$',\n",
    "            'm$', '[0-9]+k$', 'hundred(s)*', 'ten(s)*', 'one', 'two', 'three', 'four',\n",
    "            'five', 'six', 'seven', 'eight', 'nine', 'ten', 'twenty', 'thirty', 'fourty',\n",
    "            'fifty', 'sixty', 'seventy', 'eighty', 'ninety'\n",
    "        ]\n",
    "        ignore = '|'.join(regexes)\n",
    "        for token in line:\n",
    "            if re.match(ignore, token):\n",
    "                new_tokens.append('_MASKED_')\n",
    "            else:\n",
    "                new_tokens.append(token)\n",
    "        new_lines.append(new_tokens)\n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask quantitative information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737f560bae944bbb8a0e7fd9d91ff1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=909), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for transcript in tqdm.tqdm_notebook(valid_transcripts_with_stock_data):\n",
    "    text = transcript['transcript']\n",
    "    masked = mask_sentences(text)\n",
    "    unrolled = []\n",
    "    for line in masked:\n",
    "        unrolled += line\n",
    "    transcript['transcript'] = unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('masked_full_transcripts.json', 'w') as out:\n",
    "    json.dump(valid_transcripts_with_stock_data, out, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform strings to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfdc43237994a2795ae4e66f45107c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=909), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for transcript in tqdm.tqdm_notebook(valid_transcripts_with_stock_data):\n",
    "    transcript['post_high_low'] = tuple(map(float, transcript['post_high_low']))\n",
    "    historical_info = list(map(lambda x: (x[0], tuple(x[1])), transcript['historical_info']))\n",
    "    historical_info.reverse()\n",
    "    transcript['historical_info'] = historical_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cff1e7ee47045948580ecfec59f355f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=909), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for transcript in tqdm.tqdm_notebook(valid_transcripts_with_stock_data):\n",
    "    market_cap = transcript['market_cap']\n",
    "#     market_cap = re.search('[0-9]+\\.[0-9]+', market_cap)[0]\n",
    "    transcript['market_cap'] = float(market_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/processed/masked_full_transcripts.json', 'w') as out:\n",
    "    json.dump(valid_transcripts_with_stock_data, out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
