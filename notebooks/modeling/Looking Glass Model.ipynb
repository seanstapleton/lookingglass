{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator, Iterator, TabularDataset\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/processed/splits/train/stock_data.json', 'r') as inp:\n",
    "    train_stock = json.load(inp)\n",
    "with open('../../data/processed/splits/valid/stock_data.json', 'r') as inp:\n",
    "    valid_stock = json.load(inp)\n",
    "with open('../../data/processed/splits/test/stock_data.json', 'r') as inp:\n",
    "    test_stock = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = Field(\n",
    "    sequential=False\n",
    ")\n",
    "TRANSCRIPT = Field(\n",
    "    sequential=True,\n",
    "    fix_length=11000,\n",
    "    lower=True\n",
    ")\n",
    "LABEL = Field(\n",
    "    sequential=False,\n",
    "    dtype=torch.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(data.Dataset):\n",
    "    def __init__(self, examples):\n",
    "        examples = np.array(examples)\n",
    "        self.labels = examples[:,-1]\n",
    "        self.market_cap = examples[:,-2]\n",
    "        self.examples = np.array(examples[:,:-2].tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        X = torch.tensor(self.examples[index])\n",
    "        auxiliary = self.market_cap[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, auxiliary, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets():\n",
    "    train, valid, test = TabularDataset.splits(\n",
    "        path='../../data/processed/splits',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        train='train/transcripts.csv',\n",
    "        validation='valid/transcripts.csv',\n",
    "        test='test/transcripts.csv',\n",
    "        fields=[('id', ID), ('transcript', TRANSCRIPT), ('post_high', LABEL)]\n",
    "    )\n",
    "    glove = torchtext.vocab.GloVe(name='6B', dim=50)\n",
    "    TRANSCRIPT.build_vocab(train, valid, test, vectors=glove)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookingGlassDataset(data.Dataset):\n",
    "    def __init__(self, stock_dataset, transcript_dataset):\n",
    "        self.stock_data = stock_dataset\n",
    "        self.transcript_data = transcript_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.stock_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        stocks, stocks_aux, label = self.stock_data[index]\n",
    "        transcript_example = self.transcript_data[index]\n",
    "        assert math.isclose(float(transcript_example.post_high), label)\n",
    "\n",
    "        transcript = torch.tensor(transcript_example.transcript)\n",
    "        return stocks, stocks_aux, transcript, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.pkl', 'rb') as inp:\n",
    "    VOCAB = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transcripts(train, valid, test):\n",
    "    for dataset in [train, valid, test]:\n",
    "        for example in dataset:\n",
    "            if len(example.transcript) > 11000:\n",
    "                example.transcript = example.transcript[:11000]\n",
    "            else:\n",
    "                remainder = 11000 - len(example.transcript)\n",
    "                example.transcript += ['<pad>']*remainder\n",
    "            example.transcript = list(map(lambda x: VOCAB.stoi[x], example.transcript))\n",
    "    return train, valid, test\n",
    "\n",
    "train_transcript, valid_transcript, test_transcript = preprocess_transcripts(*build_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_datasets = {\n",
    "    'train': StockDataset(train_stock),\n",
    "    'valid': StockDataset(valid_stock),\n",
    "    'test': StockDataset(test_stock)\n",
    "}\n",
    "\n",
    "train_dataset = LookingGlassDataset(stock_datasets['train'], train_transcript)\n",
    "valid_dataset = LookingGlassDataset(stock_datasets['valid'], valid_transcript)\n",
    "test_dataset = LookingGlassDataset(stock_datasets['test'], test_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('vocab.pkl', 'wb') as out:\n",
    "#     pickle.dump(TRANSCRIPT.vocab, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineStockPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Model that will read in plain stock ticker values over time and decide whether to buy, sell, or hold at the current price.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_series_features=1, num_auxiliary_features=1, hidden_size=128, output_size=1):\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            num_series_features: the size of the feature set for an individual\n",
    "                                 stock price example (e.g. if we include high,\n",
    "                                 low, average, num_series_features will equal 3\n",
    "            num_auxiliary_features: the number of auxiliary (not dependent on time)\n",
    "                                    features we are adding (e.g. if we include the 1yr\n",
    "                                    high and the market capitalization, num_auxiliary_features\n",
    "                                    would equal 2\n",
    "            output_size: the size of the outputted vector. For evaluation, we would use a\n",
    "                         size of 1 (stock price) or 3 (buy, sell, hold classification).\n",
    "                         For use in the looking glass model, we want an encoding so we might\n",
    "                         use a size of 128 to feed into the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.recurrent = nn.LSTM(\n",
    "            input_size=num_series_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=False,\n",
    "            batch_first=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        # concatenate LSTM output with auxiliary features\n",
    "        # output predicted price\n",
    "        self.linear = nn.Linear(hidden_size+num_auxiliary_features, output_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes the weights of the model\n",
    "        \"\"\"\n",
    "        for layer in [self.linear]:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, X_series, X_auxiliary):\n",
    "        \"\"\"\n",
    "        Moves the model through each layer\n",
    "        Parameters:\n",
    "            X_series: an [N, num_series_examples, num_series_features] size vector\n",
    "                      where N is the batch size, num_series_examples is how many stock prices\n",
    "                      we are providing per example (e.g. weekly for the last 3 months), and\n",
    "                      num_series_features is the same as described in __init__\n",
    "            X_auxiliary: an [N, num_auxiliary_features] vector\n",
    "        \"\"\"\n",
    "        recurrent_output,_ = self.recurrent(X_series)\n",
    "        recurrent_output = torch.mean(recurrent_output, 1)\n",
    "        # We might need this\n",
    "        # recurrent_output = torch.squeeze(1) \n",
    "        aux_combined = torch.cat([recurrent_output, X_auxiliary], dim=1)\n",
    "        output = self.linear(aux_combined)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookingGlassPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Model that will use the Baseline predictor as well as earnings call information to decide whether to buy, sell, or hold at the current price\n",
    "    \"\"\"\n",
    "    def __init__(self, num_series_features=1, hidden_size=64, num_auxiliary_features=1, max_call_len=11000):\n",
    "        \"\"\"\n",
    "        Initializes the model.\n",
    "        Attributes:\n",
    "            (see baseline.py for num_series_features and num_auxiliary_features)\n",
    "            max_call_len: maximum number of tokens allowed in an earnings call transcript.\n",
    "                          We will need to pad each earnings call to be this length (or truncate\n",
    "                          if the call is too long)\n",
    "            num_auxiliary_call_features: # non-transcript related features (e.g. if we\n",
    "                                         include sentiment, ambiguity score, and\n",
    "                                         confidence score, the num_auxiliary_call_features\n",
    "                                         would equal 3\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.baseline = BaselineStockPredictor(\n",
    "            num_series_features=num_series_features,\n",
    "            num_auxiliary_features=num_auxiliary_features,\n",
    "            output_size=hidden_size\n",
    "        ).cuda()\n",
    "        self.embedding = nn.Embedding.from_pretrained(VOCAB.vectors, freeze=True)\n",
    "        self.recurrent = nn.LSTM(\n",
    "            input_size=50,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=False,\n",
    "            batch_first=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.rec_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.combined_linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.final_linear = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize the model weights\n",
    "        \"\"\"\n",
    "        self.baseline.init_weights()\n",
    "        for layer in [self.rec_linear, self.combined_linear, self.final_linear]:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, X_series, X_auxiliary, X_transcript):\n",
    "        \"\"\"\n",
    "        Moves the model through each layer\n",
    "        Parameters:\n",
    "            (see baseline.py for X_series and X_auxiliary)\n",
    "            X_transcript: an [N, max_series_features, embedding_size] vector\n",
    "            X_transcript_auxiliary: an [N, num_auxiliary_features] vector\n",
    "        \"\"\"\n",
    "        baseline_output = self.baseline.forward(X_series, X_auxiliary)\n",
    "        baseline_activated = nn.functional.relu(baseline_output)\n",
    "\n",
    "        transcript_embeddings = self.embedding(X_transcript)\n",
    "        recurrent_output,_ = self.recurrent(transcript_embeddings)\n",
    "        recurrent_output = torch.mean(recurrent_output, 1)\n",
    "        \n",
    "#         aux_combined = torch.cat([recurrent_output, X_transcript_auxiliary], dim=1)\n",
    "        output = self.rec_linear(recurrent_output)\n",
    "        output_activated = nn.functional.relu(output)\n",
    "\n",
    "        stock_transcript_joint_layer = torch.cat([baseline_activated, output_activated], dim=1)\n",
    "        z1 = self.combined_linear(stock_transcript_joint_layer)\n",
    "        a1 = nn.functional.relu(z1)\n",
    "        \n",
    "        final_output = self.final_linear(a1)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lg_iterator(dataset, batch_size, train=True, shuffle=True):\n",
    "    iterator = data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=5)\n",
    "    return iterator\n",
    "    \n",
    "def train_model(train, valid, num_epochs=200, learning_rate=0.003):\n",
    "    batch_size = 64\n",
    "    train_iterator = get_lg_iterator(train, batch_size)\n",
    "    valid_iterator = get_lg_iterator(valid, batch_size)\n",
    "    \n",
    "    model = LookingGlassPredictor(num_series_features=2, hidden_size=64)\n",
    "    model = model.float()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), learning_rate)\n",
    "    \n",
    "    losses = []\n",
    "    valid_scores = []\n",
    "    \n",
    "    min_mse = float('inf')\n",
    "    delay = 0\n",
    "    MAX_INC = 100\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(num_epochs)):\n",
    "        model.train()\n",
    "        iter_losses = []\n",
    "        print('Starting epoch', epoch)\n",
    "        for batch_stock_series, batch_stock_aux, batch_transcripts, batch_labels in train_iterator:\n",
    "            batch_stock_aux = torch.reshape(batch_stock_aux, (-1,1))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_stock_series.float().cuda(), batch_stock_aux.float().cuda(), batch_transcripts.long().cuda())\n",
    "            batch_labels = torch.reshape(batch_labels, (-1,1))\n",
    "            loss = criterion(outputs.cuda(), batch_labels.float().cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iter_losses.append(loss.item())\n",
    "        iter_losses = np.array(iter_losses)\n",
    "        losses.append(np.mean(iter_losses))\n",
    "        \n",
    "        valid_mse = []\n",
    "        model.eval()\n",
    "\n",
    "        for valid_batch_stock_series, valid_batch_stock_aux, valid_batch_transcripts, valid_batch_labels in valid_iterator:\n",
    "            valid_batch_stock_aux = torch.reshape(valid_batch_stock_aux, (-1,1))\n",
    "            outputs = model(valid_batch_stock_series.float().cuda(), valid_batch_stock_aux.float().cuda(), valid_batch_transcripts.long().cuda())\n",
    "            valid_batch_labels = torch.reshape(valid_batch_labels, (-1,1))\n",
    "            loss = criterion(outputs.cuda(), valid_batch_labels.float().cuda())\n",
    "            valid_mse.append(loss.item())\n",
    "        valid_mse = np.mean(valid_mse)\n",
    "        print(f'Completed epoch {epoch}. Valid MSE: {valid_mse}')\n",
    "\n",
    "\n",
    "        if valid_mse < min_mse:\n",
    "            min_mse = valid_mse\n",
    "            delay = 0\n",
    "            torch.save(model, 'lg_model.ckpt')\n",
    "        else:\n",
    "            delay += 1\n",
    "        if delay > MAX_INC:\n",
    "            print('Stopping early')\n",
    "            break\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanstapleton/ml/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd69ca6a30454385886d83cbd0a5d4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Completed epoch 0. Valid MSE: 23785.08984375\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanstapleton/ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LookingGlassPredictor. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/seanstapleton/ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BaselineStockPredictor. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/seanstapleton/ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/seanstapleton/ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/seanstapleton/ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 1. Valid MSE: 20688.765625\n",
      "Starting epoch 2\n",
      "Completed epoch 2. Valid MSE: 16154.099365234375\n",
      "Starting epoch 3\n",
      "Completed epoch 3. Valid MSE: 16766.5986328125\n",
      "Starting epoch 4\n",
      "Completed epoch 4. Valid MSE: 11740.748046875\n",
      "Starting epoch 5\n",
      "Completed epoch 5. Valid MSE: 7772.623291015625\n",
      "Starting epoch 6\n",
      "Completed epoch 6. Valid MSE: 4198.9544677734375\n",
      "Starting epoch 7\n",
      "Completed epoch 7. Valid MSE: 1839.4732971191406\n",
      "Starting epoch 8\n",
      "Completed epoch 8. Valid MSE: 2023.5560302734375\n",
      "Starting epoch 9\n",
      "Completed epoch 9. Valid MSE: 1521.7385864257812\n",
      "Starting epoch 10\n",
      "Completed epoch 10. Valid MSE: 4094.26904296875\n",
      "Starting epoch 11\n",
      "Completed epoch 11. Valid MSE: 1079.9304809570312\n",
      "Starting epoch 12\n",
      "Completed epoch 12. Valid MSE: 517.68017578125\n",
      "Starting epoch 13\n",
      "Completed epoch 13. Valid MSE: 330.5074157714844\n",
      "Starting epoch 14\n",
      "Completed epoch 14. Valid MSE: 660.12451171875\n",
      "Starting epoch 15\n",
      "Completed epoch 15. Valid MSE: 417.8621520996094\n",
      "Starting epoch 16\n",
      "Completed epoch 16. Valid MSE: 506.4829559326172\n",
      "Starting epoch 17\n",
      "Completed epoch 17. Valid MSE: 905.3525695800781\n",
      "Starting epoch 18\n",
      "Completed epoch 18. Valid MSE: 3103.76220703125\n",
      "Starting epoch 19\n",
      "Completed epoch 19. Valid MSE: 3273.4632568359375\n",
      "Starting epoch 20\n",
      "Completed epoch 20. Valid MSE: 786.0824279785156\n",
      "Starting epoch 21\n",
      "Completed epoch 21. Valid MSE: 760.7263641357422\n",
      "Starting epoch 22\n",
      "Completed epoch 22. Valid MSE: 620.8373565673828\n",
      "Starting epoch 23\n",
      "Completed epoch 23. Valid MSE: 1020.4908752441406\n",
      "Starting epoch 24\n",
      "Completed epoch 24. Valid MSE: 627.5092163085938\n",
      "Starting epoch 25\n",
      "Completed epoch 25. Valid MSE: 1276.5242309570312\n",
      "Starting epoch 26\n",
      "Completed epoch 26. Valid MSE: 696.3776550292969\n",
      "Starting epoch 27\n",
      "Completed epoch 27. Valid MSE: 1778.5157470703125\n",
      "Starting epoch 28\n",
      "Completed epoch 28. Valid MSE: 2064.111572265625\n",
      "Starting epoch 29\n",
      "Completed epoch 29. Valid MSE: 1596.0360717773438\n",
      "Starting epoch 30\n",
      "Completed epoch 30. Valid MSE: 586.2161254882812\n",
      "Starting epoch 31\n",
      "Completed epoch 31. Valid MSE: 1187.2329711914062\n",
      "Starting epoch 32\n",
      "Completed epoch 32. Valid MSE: 3552.670654296875\n",
      "Starting epoch 33\n",
      "Completed epoch 33. Valid MSE: 2415.63232421875\n",
      "Starting epoch 34\n",
      "Completed epoch 34. Valid MSE: 1350.7442016601562\n",
      "Starting epoch 35\n",
      "Completed epoch 35. Valid MSE: 569.8953704833984\n",
      "Starting epoch 36\n",
      "Completed epoch 36. Valid MSE: 1112.4142456054688\n",
      "Starting epoch 37\n",
      "Completed epoch 37. Valid MSE: 843.7101745605469\n",
      "Starting epoch 38\n",
      "Completed epoch 38. Valid MSE: 394.86627197265625\n",
      "Starting epoch 39\n",
      "Completed epoch 39. Valid MSE: 1054.4596862792969\n",
      "Starting epoch 40\n",
      "Completed epoch 40. Valid MSE: 724.6733551025391\n",
      "Starting epoch 41\n",
      "Completed epoch 41. Valid MSE: 1185.6722564697266\n",
      "Starting epoch 42\n",
      "Completed epoch 42. Valid MSE: 472.6969451904297\n",
      "Starting epoch 43\n",
      "Completed epoch 43. Valid MSE: 497.6797180175781\n",
      "Starting epoch 44\n",
      "Completed epoch 44. Valid MSE: 1798.9586181640625\n",
      "Starting epoch 45\n",
      "Completed epoch 45. Valid MSE: 2315.3541259765625\n",
      "Starting epoch 46\n",
      "Completed epoch 46. Valid MSE: 439.61024475097656\n",
      "Starting epoch 47\n",
      "Completed epoch 47. Valid MSE: 1379.5543212890625\n",
      "Starting epoch 48\n",
      "Completed epoch 48. Valid MSE: 373.32997131347656\n",
      "Starting epoch 49\n",
      "Completed epoch 49. Valid MSE: 918.5601196289062\n",
      "Starting epoch 50\n",
      "Completed epoch 50. Valid MSE: 1016.1865539550781\n",
      "Starting epoch 51\n",
      "Completed epoch 51. Valid MSE: 1058.7644348144531\n",
      "Starting epoch 52\n",
      "Completed epoch 52. Valid MSE: 561.4153137207031\n",
      "Starting epoch 53\n",
      "Completed epoch 53. Valid MSE: 873.0754089355469\n",
      "Starting epoch 54\n",
      "Completed epoch 54. Valid MSE: 2354.227294921875\n",
      "Starting epoch 55\n",
      "Completed epoch 55. Valid MSE: 3099.6492919921875\n",
      "Starting epoch 56\n",
      "Completed epoch 56. Valid MSE: 9448.97412109375\n",
      "Starting epoch 57\n",
      "Completed epoch 57. Valid MSE: 2614.8450927734375\n",
      "Starting epoch 58\n",
      "Completed epoch 58. Valid MSE: 3912.6857299804688\n",
      "Starting epoch 59\n",
      "Completed epoch 59. Valid MSE: 1380.0729370117188\n",
      "Starting epoch 60\n",
      "Completed epoch 60. Valid MSE: 2214.9805297851562\n",
      "Starting epoch 61\n",
      "Completed epoch 61. Valid MSE: 562.4095001220703\n",
      "Starting epoch 62\n",
      "Completed epoch 62. Valid MSE: 3539.463623046875\n",
      "Starting epoch 63\n",
      "Completed epoch 63. Valid MSE: 924.5409545898438\n",
      "Starting epoch 64\n",
      "Completed epoch 64. Valid MSE: 669.3265991210938\n",
      "Starting epoch 65\n",
      "Completed epoch 65. Valid MSE: 754.2660827636719\n",
      "Starting epoch 66\n",
      "Completed epoch 66. Valid MSE: 360.8908462524414\n",
      "Starting epoch 67\n",
      "Completed epoch 67. Valid MSE: 761.7170715332031\n",
      "Starting epoch 68\n",
      "Completed epoch 68. Valid MSE: 1458.007568359375\n",
      "Starting epoch 69\n",
      "Completed epoch 69. Valid MSE: 1351.3110656738281\n",
      "Starting epoch 70\n",
      "Completed epoch 70. Valid MSE: 1732.7860412597656\n",
      "Starting epoch 71\n",
      "Completed epoch 71. Valid MSE: 952.1379699707031\n",
      "Starting epoch 72\n",
      "Completed epoch 72. Valid MSE: 663.3406372070312\n",
      "Starting epoch 73\n",
      "Completed epoch 73. Valid MSE: 509.37255859375\n",
      "Starting epoch 74\n",
      "Completed epoch 74. Valid MSE: 358.07310485839844\n",
      "Starting epoch 75\n",
      "Completed epoch 75. Valid MSE: 419.05580139160156\n",
      "Starting epoch 76\n",
      "Completed epoch 76. Valid MSE: 345.0120315551758\n",
      "Starting epoch 77\n",
      "Completed epoch 77. Valid MSE: 468.93931579589844\n",
      "Starting epoch 78\n",
      "Completed epoch 78. Valid MSE: 311.385009765625\n",
      "Starting epoch 79\n",
      "Completed epoch 79. Valid MSE: 172.63302612304688\n",
      "Starting epoch 80\n",
      "Completed epoch 80. Valid MSE: 252.0779571533203\n",
      "Starting epoch 81\n",
      "Completed epoch 81. Valid MSE: 681.0120239257812\n",
      "Starting epoch 82\n",
      "Completed epoch 82. Valid MSE: 428.1619873046875\n",
      "Starting epoch 83\n",
      "Completed epoch 83. Valid MSE: 668.413818359375\n",
      "Starting epoch 84\n",
      "Completed epoch 84. Valid MSE: 417.51810455322266\n",
      "Starting epoch 85\n",
      "Completed epoch 85. Valid MSE: 343.02647399902344\n",
      "Starting epoch 86\n",
      "Completed epoch 86. Valid MSE: 323.0138397216797\n",
      "Starting epoch 87\n",
      "Completed epoch 87. Valid MSE: 346.61329650878906\n",
      "Starting epoch 88\n",
      "Completed epoch 88. Valid MSE: 583.9797973632812\n",
      "Starting epoch 89\n",
      "Completed epoch 89. Valid MSE: 1494.8331909179688\n",
      "Starting epoch 90\n",
      "Completed epoch 90. Valid MSE: 821.0210266113281\n",
      "Starting epoch 91\n",
      "Completed epoch 91. Valid MSE: 911.6114501953125\n",
      "Starting epoch 92\n",
      "Completed epoch 92. Valid MSE: 9417.060546875\n",
      "Starting epoch 93\n",
      "Completed epoch 93. Valid MSE: 1447.5992126464844\n",
      "Starting epoch 94\n",
      "Completed epoch 94. Valid MSE: 1284.350341796875\n",
      "Starting epoch 95\n",
      "Completed epoch 95. Valid MSE: 922.6936340332031\n",
      "Starting epoch 96\n",
      "Completed epoch 96. Valid MSE: 975.0736846923828\n",
      "Starting epoch 97\n",
      "Completed epoch 97. Valid MSE: 515.3865966796875\n",
      "Starting epoch 98\n",
      "Completed epoch 98. Valid MSE: 2009.13818359375\n",
      "Starting epoch 99\n",
      "Completed epoch 99. Valid MSE: 8279.87646484375\n",
      "Starting epoch 100\n",
      "Completed epoch 100. Valid MSE: 1104.4562377929688\n",
      "Starting epoch 101\n",
      "Completed epoch 101. Valid MSE: 2930.390625\n",
      "Starting epoch 102\n",
      "Completed epoch 102. Valid MSE: 2006.7928466796875\n",
      "Starting epoch 103\n",
      "Completed epoch 103. Valid MSE: 1164.5086975097656\n",
      "Starting epoch 104\n",
      "Completed epoch 104. Valid MSE: 891.8309936523438\n",
      "Starting epoch 105\n",
      "Completed epoch 105. Valid MSE: 924.2844848632812\n",
      "Starting epoch 106\n",
      "Completed epoch 106. Valid MSE: 526.8466644287109\n",
      "Starting epoch 107\n",
      "Completed epoch 107. Valid MSE: 307.75547790527344\n",
      "Starting epoch 108\n",
      "Completed epoch 108. Valid MSE: 439.93601989746094\n",
      "Starting epoch 109\n",
      "Completed epoch 109. Valid MSE: 963.53759765625\n",
      "Starting epoch 110\n",
      "Completed epoch 110. Valid MSE: 1687.9114990234375\n",
      "Starting epoch 111\n",
      "Completed epoch 111. Valid MSE: 545.6636810302734\n",
      "Starting epoch 112\n",
      "Completed epoch 112. Valid MSE: 2836.685546875\n",
      "Starting epoch 113\n",
      "Completed epoch 113. Valid MSE: 1023.8675842285156\n",
      "Starting epoch 114\n",
      "Completed epoch 114. Valid MSE: 1721.3606567382812\n",
      "Starting epoch 115\n",
      "Completed epoch 115. Valid MSE: 1167.0218811035156\n",
      "Starting epoch 116\n",
      "Completed epoch 116. Valid MSE: 572.3872375488281\n",
      "Starting epoch 117\n",
      "Completed epoch 117. Valid MSE: 2458.795166015625\n",
      "Starting epoch 118\n",
      "Completed epoch 118. Valid MSE: 1175.0643310546875\n",
      "Starting epoch 119\n",
      "Completed epoch 119. Valid MSE: 814.4027404785156\n",
      "Starting epoch 120\n",
      "Completed epoch 120. Valid MSE: 446.1918258666992\n",
      "Starting epoch 121\n",
      "Completed epoch 121. Valid MSE: 676.9349365234375\n",
      "Starting epoch 122\n",
      "Completed epoch 122. Valid MSE: 2082.185302734375\n",
      "Starting epoch 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 123. Valid MSE: 822.9580841064453\n",
      "Starting epoch 124\n",
      "Completed epoch 124. Valid MSE: 987.074951171875\n",
      "Starting epoch 125\n",
      "Completed epoch 125. Valid MSE: 863.0892333984375\n",
      "Starting epoch 126\n",
      "Completed epoch 126. Valid MSE: 355.7365531921387\n",
      "Starting epoch 127\n",
      "Completed epoch 127. Valid MSE: 539.4450836181641\n",
      "Starting epoch 128\n",
      "Completed epoch 128. Valid MSE: 525.7629547119141\n",
      "Starting epoch 129\n",
      "Completed epoch 129. Valid MSE: 638.437744140625\n",
      "Starting epoch 130\n",
      "Completed epoch 130. Valid MSE: 761.9725646972656\n",
      "Starting epoch 131\n",
      "Completed epoch 131. Valid MSE: 557.3621520996094\n",
      "Starting epoch 132\n",
      "Completed epoch 132. Valid MSE: 525.2748565673828\n",
      "Starting epoch 133\n",
      "Completed epoch 133. Valid MSE: 850.2799682617188\n",
      "Starting epoch 134\n",
      "Completed epoch 134. Valid MSE: 1857.0657958984375\n",
      "Starting epoch 135\n",
      "Completed epoch 135. Valid MSE: 791.0437316894531\n",
      "Starting epoch 136\n",
      "Completed epoch 136. Valid MSE: 517.6451416015625\n",
      "Starting epoch 137\n",
      "Completed epoch 137. Valid MSE: 1460.2432861328125\n",
      "Starting epoch 138\n",
      "Completed epoch 138. Valid MSE: 399.8374786376953\n",
      "Starting epoch 139\n",
      "Completed epoch 139. Valid MSE: 451.5528259277344\n",
      "Starting epoch 140\n",
      "Completed epoch 140. Valid MSE: 1512.4408874511719\n",
      "Starting epoch 141\n",
      "Completed epoch 141. Valid MSE: 412.3150939941406\n",
      "Starting epoch 142\n",
      "Completed epoch 142. Valid MSE: 512.0616149902344\n",
      "Starting epoch 143\n",
      "Completed epoch 143. Valid MSE: 1229.1207275390625\n",
      "Starting epoch 144\n",
      "Completed epoch 144. Valid MSE: 890.7199096679688\n",
      "Starting epoch 145\n",
      "Completed epoch 145. Valid MSE: 387.75122833251953\n",
      "Starting epoch 146\n",
      "Completed epoch 146. Valid MSE: 648.8464050292969\n",
      "Starting epoch 147\n",
      "Completed epoch 147. Valid MSE: 942.0435180664062\n",
      "Starting epoch 148\n",
      "Completed epoch 148. Valid MSE: 838.2389526367188\n",
      "Starting epoch 149\n",
      "Completed epoch 149. Valid MSE: 3342.880615234375\n",
      "Starting epoch 150\n",
      "Completed epoch 150. Valid MSE: 524.1605377197266\n",
      "Starting epoch 151\n",
      "Completed epoch 151. Valid MSE: 1394.1233673095703\n",
      "Starting epoch 152\n",
      "Completed epoch 152. Valid MSE: 617.1947937011719\n",
      "Starting epoch 153\n",
      "Completed epoch 153. Valid MSE: 768.4671936035156\n",
      "Starting epoch 154\n",
      "Completed epoch 154. Valid MSE: 1365.4141235351562\n",
      "Starting epoch 155\n",
      "Completed epoch 155. Valid MSE: 356.7356414794922\n",
      "Starting epoch 156\n",
      "Completed epoch 156. Valid MSE: 481.6698303222656\n",
      "Starting epoch 157\n",
      "Completed epoch 157. Valid MSE: 587.2849731445312\n",
      "Starting epoch 158\n",
      "Completed epoch 158. Valid MSE: 406.7025680541992\n",
      "Starting epoch 159\n",
      "Completed epoch 159. Valid MSE: 740.4187927246094\n",
      "Starting epoch 160\n",
      "Completed epoch 160. Valid MSE: 851.88427734375\n",
      "Starting epoch 161\n",
      "Completed epoch 161. Valid MSE: 4213.6365966796875\n",
      "Starting epoch 162\n",
      "Completed epoch 162. Valid MSE: 1500.5294189453125\n",
      "Starting epoch 163\n",
      "Completed epoch 163. Valid MSE: 1116.1181640625\n",
      "Starting epoch 164\n",
      "Completed epoch 164. Valid MSE: 4827.369140625\n",
      "Starting epoch 165\n",
      "Completed epoch 165. Valid MSE: 5083.962646484375\n",
      "Starting epoch 166\n",
      "Completed epoch 167. Valid MSE: 1206.8963012695312\n",
      "Starting epoch 168\n",
      "Completed epoch 168. Valid MSE: 4029.706787109375\n",
      "Starting epoch 169\n",
      "Completed epoch 169. Valid MSE: 3220.8482666015625\n",
      "Starting epoch 170\n",
      "Completed epoch 170. Valid MSE: 1078.1414794921875\n",
      "Starting epoch 171\n",
      "Completed epoch 171. Valid MSE: 596.9754333496094\n",
      "Starting epoch 172\n",
      "Completed epoch 172. Valid MSE: 325.78309631347656\n",
      "Starting epoch 173\n",
      "Completed epoch 173. Valid MSE: 566.3771667480469\n",
      "Starting epoch 174\n",
      "Completed epoch 174. Valid MSE: 328.0641632080078\n",
      "Starting epoch 175\n",
      "Completed epoch 175. Valid MSE: 570.98095703125\n",
      "Starting epoch 176\n",
      "Completed epoch 176. Valid MSE: 792.0661010742188\n",
      "Starting epoch 177\n",
      "Completed epoch 177. Valid MSE: 808.3533325195312\n",
      "Starting epoch 178\n",
      "Completed epoch 178. Valid MSE: 426.4361877441406\n",
      "Starting epoch 179\n",
      "Completed epoch 179. Valid MSE: 280.30088806152344\n",
      "Starting epoch 180\n",
      "Completed epoch 180. Valid MSE: 351.7367973327637\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "model = train_model(train_dataset, valid_dataset, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test):\n",
    "    batch_size = 64\n",
    "    test_iterator = get_lg_iterator(test, batch_size)\n",
    "    model.eval()\n",
    "        \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    losses = []\n",
    "    for batch_stock_series, batch_stock_aux, batch_transcripts, batch_labels in test_iterator:\n",
    "        batch_stock_aux = torch.reshape(batch_stock_aux, (-1,1))\n",
    "        outputs = model(batch_stock_series.float().cuda(), batch_stock_aux.float().cuda(), batch_transcripts.long().cuda())\n",
    "        batch_labels = torch.reshape(batch_labels, (-1,1))\n",
    "        loss = criterion(outputs.cuda(), batch_labels.float().cuda())\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.0254936218262"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model[0], test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lg_losses_180_epochs.json', 'w') as out:\n",
    "    json.dump(model[1], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
